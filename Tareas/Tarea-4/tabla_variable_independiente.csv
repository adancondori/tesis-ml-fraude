Dimensión,Indicador,Técnica,Instrumento,Actividades Concretas
"1.1. Feature engineering y entrenamiento inicial","1.1.1. Feature Importance por variable","ML supervisado con Random Forest","Python (scikit-learn, pandas)","(1) Conectar a ClickHouse de TechSport. (2) Extraer 15.7M transacciones 2025. (3) Feature engineering: crear 15+ variables (tx_count_24h, amount_z_score, hour_of_day, is_weekend, gateway_risk_score, etc.). (4) Entrenar Random Forest (n_estimators=200, max_depth=15). (5) Extraer feature_importances_ y ordenar. (6) Visualizar top 10 en gráfico de barras. (7) Guardar en figuras/feature_importance.png."
"1.1. Feature engineering y entrenamiento inicial","1.1.2. Distribución de features transformadas","EDA con visualizaciones","matplotlib, seaborn","(1) Cargar dataset limpio. (2) Generar histogramas y boxplots por feature numérica. (3) Detectar outliers con método IQR. (4) Aplicar normalización Min-Max a features numéricas. (5) Generar reporte estadístico (describe()) y exportar a LaTeX."
"1.1. Feature engineering y entrenamiento inicial","1.1.3. Métricas de entrenamiento: F1, Precision, Recall","Evaluación de modelo supervisado","classification_report(), confusion_matrix()","(1) Predecir en train set (y_pred). (2) Calcular matriz de confusión. (3) Extraer VP, VN, FP, FN. (4) Calcular F1, Precision, Recall. (5) Generar classification_report. (6) Repetir para validation set. (7) Guardar métricas en CSV comparativo."
"1.1. Feature engineering y entrenamiento inicial","1.1.4. Ratio de balanceo de clases (%)","Balanceo de datos","SMOTE (imblearn) o class_weight","(1) Analizar distribución de is_fraud con value_counts(). (2) Calcular ratio fraude/no-fraude. (3) Si ratio > 10:1, aplicar SMOTE con sampling_strategy=0.5. (4) Verificar nuevo ratio post-SMOTE. (5) Documentar decisión y comparar métricas. Alternativa: class_weight='balanced'."
"1.1. Feature engineering y entrenamiento inicial","1.1.5. Tiempo de inferencia (ms)","Benchmarking de performance","time.time()","(1) Seleccionar muestra de 10K transacciones de test set. (2) Medir tiempo con time.time() antes/después de predicción. (3) Calcular tiempo promedio por transacción. (4) Repetir 10 veces. (5) Calcular IC 95%. (6) Verificar que cumple objetivo < 200ms."
"1.2. Selección y optimización de algoritmo","1.2.1. Comparación RF vs. XGBoost vs. SVM","Análisis comparativo cuantitativo","GridSearchCV, métricas F1 y AUC-ROC","(1) Definir 3 algoritmos: models = {'RF': RandomForestClassifier(), 'XGB': XGBClassifier(), 'SVM': SVC()}. (2) Entrenar en train set. (3) Predecir en validation: y_pred = model.predict(X_val). (4) Calcular F1-Score. (5) Calcular AUC-ROC. (6) Crear tabla comparativa LaTeX. (7) Seleccionar mejor modelo. (8) Justificar: Random Forest: F1=0.872, AUC=0.935."
"1.2. Selección y optimización de algoritmo","1.2.2. Hiperparámetros optimizados","Optimización con GridSearchCV","GridSearchCV k-fold (k=5)","(1) Definir espacio: param_grid = {'n_estimators': [100,200,300], 'max_depth': [10,15,20]}. (2) Configurar GridSearchCV: grid = GridSearchCV(RF, param_grid, cv=5, scoring='f1'). (3) Ejecutar: grid.fit(X_train, y_train) (6-8 hrs). (4) Extraer óptimos: best_params. (5) Evaluar en validation. (6) Documentar: Óptimos: n_estimators=200, max_depth=15. F1 val: 0.883."
"1.2. Selección y optimización de algoritmo","1.2.3. Gap overfitting (train vs. validation)","Análisis de learning curves","Logs entrenamiento, scikit-learn","(1) Calcular accuracy en train: acc_train = accuracy_score(y_train, rf.predict(X_train)). (2) Calcular en validation: acc_val. (3) Calcular gap: gap = abs(acc_train - acc_val) * 100. (4) Evaluar: gap < 5% → generaliza bien. (5) Generar learning curve. (6) Visualizar con matplotlib. (7) Documentar: Gap: 3.2%, buen balance."
"1.2. Selección y optimización de algoritmo","1.2.4. Tamaño modelo serializado (MB)","Serialización con joblib","Comando ls -lh","(1) Serializar: joblib.dump(rf, 'models/rf_final.pkl', compress=3). (2) Verificar tamaño: ls -lh models/rf_final.pkl. (3) Documentar: 342 MB comprimido. (4) Evaluar viabilidad: si > 500 MB, reducir n_estimators. (5) Medir tiempo carga: time.time(). (6) Documentar: Tiempo carga: 2.3s."
