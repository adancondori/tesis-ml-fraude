% ==================================================================================
% CAPÍTULO 5: CONCLUSIONES Y RECOMENDACIONES
% ==================================================================================

\chapter{Conclusiones y Recomendaciones}
\label{cap:conclusiones}

\section{Introducción}

El presente capítulo sintetiza los hallazgos principales de la investigación, contrastando los resultados obtenidos con los objetivos planteados en el perfil de tesis. Se presentan conclusiones estructuradas en dos niveles: (1) conclusión general que responde al Objetivo General, y (2) conclusiones específicas alineadas con cada uno de los cuatro Objetivos Específicos (OE1-OE4). Posteriormente, se formulan recomendaciones técnicas, organizacionales y académicas derivadas de los aprendizajes del estudio, seguidas de una discusión sobre las limitaciones metodológicas y las contribuciones de la investigación al campo de la detección de fraude en pagos transaccionales.

\section{Conclusiones}

\subsection{Conclusión General}

La investigación cumple satisfactoriamente con el Objetivo General planteado: ``\textit{Implementar un modelo de Machine Learning supervisado basado en Random Forest para la detección de transacciones fraudulentas y anómalas en pagos digitales, logrando un F1-Score $\geq$ 85\%, Recall $\geq$ 90\%, Precision $\geq$ 80\%, AUC-ROC $\geq$ 0.92 y tiempos de inferencia < 200 ms}''.

\textbf{Evidencia del cumplimiento:}

\begin{itemize}[leftmargin=*]
    \item El modelo Random Forest optimizado mediante Grid Search alcanza un \textbf{F1-Score de 88.42\%}, superando el umbral mínimo del 85\% en 3.42 puntos porcentuales. Este resultado demuestra un balance efectivo entre Precision y Recall en el contexto de clases desbalanceadas (0.51\% de fraudes).

    \item El \textbf{Recall de 92.17\%} supera el objetivo del 90\%, indicando que el modelo detecta aproximadamente 9 de cada 10 transacciones fraudulentas presentes en el conjunto de validación temporal 2025. Este alto Recall minimiza el riesgo de fraudes no detectados (falsos negativos), crítico en aplicaciones de seguridad financiera.

    \item La \textbf{Precision de 85.04\%} excede el umbral del 80\%, demostrando que 8.5 de cada 10 alertas generadas por el modelo corresponden a fraudes reales. Este nivel de Precision reduce la carga operativa del equipo de revisión manual, evitando la saturación de alertas falsas.

    \item El \textbf{AUC-ROC de 0.9521} supera el objetivo de 0.92, posicionando el modelo en el rango ``excelente'' de capacidad discriminativa según estándares de evaluación de modelos predictivos. Este valor indica una probabilidad del 95.21\% de que el modelo asigne mayor puntuación de riesgo a una transacción fraudulenta que a una legítima.

    \item Los \textbf{tiempos de inferencia promedio de 124 ms} y percentil 95 de 186 ms cumplen con el requisito de < 200 ms, validando la viabilidad del modelo para despliegue en sistemas de detección en tiempo real donde la latencia de respuesta es crítica.

    \item La \textbf{validación estadística mediante intervalos de confianza bootstrap} al 95\% con 1000 muestras confirma que los límites inferiores de todas las métricas superan los umbrales establecidos, proporcionando robustez estadística a las conclusiones.
\end{itemize}

\textbf{Impacto operacional y financiero:}

El análisis de costos de errores demuestra que el modelo logra una \textbf{reducción del 91.76\% en pérdidas por fraude} comparado con el escenario sin detección automática, equivalente a un ahorro estimado de \textbf{\$24.95 millones USD} en el periodo de validación (año 2025). Este resultado valida la viabilidad económica y operacional de la solución propuesta para entornos de pagos digitales a escala empresarial.

\textbf{Validación de hipótesis:}

La hipótesis general del estudio establece: ``\textit{La implementación de un modelo de Machine Learning supervisado basado en Random Forest con features comportamentales engineered y validación temporal estricta permite detectar transacciones fraudulentas y anómalas en pagos digitales con F1-Score $\geq$ 85\%, superando las limitaciones de sistemas basados en reglas estáticas}''. Los resultados empíricos respaldan plenamente esta hipótesis, demostrando que:

\begin{enumerate}[leftmargin=*]
    \item El enfoque de \textbf{feature engineering comportamental} (17 features, con 62.69\% de importancia acumulada en las top 5 features comportamentales) permite capturar patrones de fraude más robustos que features transaccionales básicas.

    \item La \textbf{validación temporal estricta} (train 2024, test 2025) con prevención de data leakage garantiza que el modelo generaliza adecuadamente a datos futuros no vistos, simulando condiciones reales de despliegue.

    \item El algoritmo \textbf{Random Forest} demuestra desempeño competitivo frente a alternativas más complejas (Deep Learning, XGBoost), ofreciendo además ventajas en interpretabilidad, estabilidad y menores requisitos computacionales.
\end{enumerate}

\subsection{Conclusiones Específicas}

\subsubsection{Conclusión en relación al Objetivo Específico 1 (OE1)}

\textbf{OE1:} ``\textit{Fundamentar teóricamente los conceptos de fraude en pagos transaccionales, algoritmos de Machine Learning supervisado, feature engineering comportamental y validación temporal, mediante revisión de literatura científica actualizada (2018-2025), identificando benchmarks de F1-Score entre 85-94\% como referencia comparativa}''.

\textbf{Conclusión:}

La revisión sistemática de literatura científica presentada en el Capítulo 1 (Marco Teórico) establece un fundamento teórico robusto que sustenta las decisiones metodológicas del estudio. Los principales aportes teóricos incluyen:

\begin{enumerate}[leftmargin=*]
    \item \textbf{Caracterización de fraude en pagos digitales:} Se identificaron tres tipologías dominantes de fraude en el dataset de TechSport: tarjetas robadas (62\%), tarjetas duplicadas (23\%) y comportamiento anómalo (15\%). Esta caracterización valida la relevancia del estudio en contextos reales de fraude.

    \item \textbf{Benchmarks de literatura:} Se documentaron benchmarks de F1-Score entre 85-94\% para modelos de Random Forest (Hafez et al., 2025) y XGBoost (Feng et al., 2024) sobre datasets de fraude en pagos. El modelo desarrollado (F1: 88.42\%) se posiciona en el rango superior de estos benchmarks, demostrando competitividad frente al estado del arte.

    \item \textbf{Feature engineering comportamental:} La revisión teórica fundamenta la superioridad de features basadas en comportamiento histórico del usuario (frecuencia transaccional, velocidad, desviación de patrones) sobre features transaccionales estáticas. Esta fundamentación se valida empíricamente en el Capítulo 4, donde las features comportamentales dominan el ranking de importancia (62.69\% acumulado).

    \item \textbf{Validación temporal:} Se fundamenta la necesidad de validación temporal estricta (train histórico, test futuro) como alternativa a k-fold cross-validation en datos con dependencia temporal. Esta decisión metodológica previene data leakage y garantiza evaluación realista del modelo.

    \item \textbf{Marco normativo PCI DSS:} Se documenta el cumplimiento del modelo con estándares de seguridad de la industria de pagos (Payment Card Industry Data Security Standard), validando su viabilidad para despliegue en entornos regulados.
\end{enumerate}

\textbf{Implicación metodológica:} El fundamento teórico robusto permite justificar cada decisión metodológica del estudio (selección de algoritmo, estrategia de feature engineering, técnica de validación), incrementando la rigurosidad científica de la investigación.

\subsubsection{Conclusión en relación al Objetivo Específico 2 (OE2)}

\textbf{OE2:} ``\textit{Diseñar la metodología de investigación bajo enfoque cuantitativo con diseño cuasiexperimental retrospectivo, operacionalizando la Variable Madre (Transacciones fraudulentas y anómalas) mediante 8 indicadores de fraude y estableciendo validación temporal estricta sobre dataset de 25.2M transacciones (2024-2025) con tasa de fraude 0.51\%}''.

\textbf{Conclusión:}

El diseño metodológico cuasiexperimental retrospectivo implementado en el Capítulo 2 (Metodología) cumple con los requisitos de rigurosidad científica para investigaciones en Machine Learning aplicado a detección de fraude. Los principales logros metodológicos incluyen:

\begin{enumerate}[leftmargin=*]
    \item \textbf{Operacionalización de la Variable Madre:} La Variable Dependiente ``Transacciones fraudulentas y anómalas'' se operacionalizó mediante 8 indicadores cuantificables: (1) F1-Score, (2) Recall, (3) Precision, (4) AUC-ROC, (5) Accuracy, (6) FPR, (7) FNR, y (8) tiempo de inferencia. Esta operacionalización permite una evaluación multidimensional del desempeño del modelo, evitando sesgos asociados a métricas únicas.

    \item \textbf{Dataset de escala empresarial:} El estudio utiliza un dataset de 25,254,872 transacciones reales (2024-2025) de TechSport, con cobertura del 74.60\% de transacciones totales del periodo. Esta escala supera significativamente a la mayoría de estudios en literatura (típicamente < 500K transacciones), reflejando mejor las condiciones operacionales de sistemas de pago reales.

    \item \textbf{Desbalance de clases realista:} La tasa de fraude del 0.51\% (< 1\%) representa condiciones reales de fraude en pagos digitales, donde la clase minoritaria es extremadamente rara. El manejo de este desbalance mediante SMOTE balancing (ratio 50/50 en entrenamiento) demuestra efectividad, logrando Recall del 92.17\% sin sacrificar excesivamente la Precision (85.04\%).

    \item \textbf{Validación temporal estricta:} La partición temporal train/test (2024: 9.7M transacciones, 2025: 15.5M transacciones) con prevención rigurosa de data leakage (\texttt{closed='left'}, \texttt{shift(1)}, ordenamiento temporal estricto) garantiza que el modelo se evalúa sobre datos futuros no vistos, simulando despliegue en producción. Esta estrategia supera metodológicamente a estudios que utilizan k-fold cross-validation sobre datos mezclados temporalmente.

    \item \textbf{Alineación OG-OE-Variable Madre:} El diseño metodológico establece trazabilidad explícita entre Objetivo General, Objetivos Específicos, Variable Madre e indicadores de medición, cumpliendo con criterios de coherencia interna recomendados por metodología AQP/CCA (Martínez, 2020) y Sampieri et al. (2014).
\end{enumerate}

\textbf{Implicación metodológica:} El diseño cuasiexperimental retrospectivo es apropiado para contextos donde no es posible manipular variables independientes ni asignar aleatoriamente grupos (condición inherente a datos históricos de fraude). La metodología implementada puede replicarse en estudios similares de detección de fraude en otros sectores financieros.

\subsubsection{Conclusión en relación al Objetivo Específico 3 (OE3)}

\textbf{OE3:} ``\textit{Desarrollar el modelo de Machine Learning supervisado mediante preprocesamiento del dataset histórico, feature engineering evitando data leakage, balanceo de clases adaptativo y validación temporal, generando mínimo 15 features comportamentales}''.

\textbf{Conclusión:}

El proceso de desarrollo del modelo presentado en el Capítulo 3 (Desarrollo e Implementación) cumple con todos los requisitos técnicos establecidos, alcanzando estándares de calidad de ingeniería de software para sistemas de Machine Learning en producción. Los principales logros técnicos incluyen:

\begin{enumerate}[leftmargin=*]
    \item \textbf{Pipeline de preprocesamiento robusto:} Se implementó un pipeline completo que incluye: (a) tratamiento de valores faltantes mediante imputación domain-specific (medianas para features numéricas, moda para categóricas), (b) detección y tratamiento de outliers mediante Winsorization (percentiles 1\% y 99\%), (c) eliminación de duplicados exactos (0.02\% del dataset), y (d) normalización de features numéricas mediante StandardScaler. Este preprocesamiento garantiza calidad de datos para el entrenamiento del modelo.

    \item \textbf{Feature engineering exhaustivo:} Se generaron 17 features comportamentales (superando el mínimo de 15 especificado), categorizadas en: (a) temporales (4 features: hora\_del\_dia, dia\_semana, es\_fin\_de\_semana, es\_horario\_nocturno), (b) frecuenciales (2 features: frecuencia\_24h, frecuencia\_7d), (c) comportamiento de monto (4 features: monto\_promedio\_historico, ratio\_monto\_vs\_promedio, monto\_desviacion\_std, monto\_normalizado), (d) velocidad (2 features: tiempo\_desde\_ultima\_trans, velocidad\_transaccional), (e) perfil de usuario (1 feature: es\_usuario\_nuevo), (f) geográficas (1 feature: distancia\_ip\_tarjeta), y (g) canal (3 features: one-hot encoding de canal transaccional). Esta riqueza de features permite al modelo capturar patrones complejos de fraude.

    \item \textbf{Prevención rigurosa de data leakage:} Se documentaron e implementaron técnicas críticas para evitar data leakage temporal: (a) uso de \texttt{closed='left'} en rolling windows para excluir la transacción actual del cálculo de estadísticas agregadas, (b) uso de \texttt{shift(1)} para desplazar valores históricos y evitar uso de información futura, (c) ordenamiento estricto por timestamp antes de partición train/test, y (d) cálculo de estadísticas agregadas únicamente sobre datos del conjunto de entrenamiento. Esta rigurosidad garantiza validez de las métricas reportadas.

    \item \textbf{Balanceo adaptativo SMOTE:} Se aplicó Synthetic Minority Oversampling Technique (SMOTE) con ratio 50/50 sobre el conjunto de entrenamiento, generando muestras sintéticas de la clase minoritaria mediante interpolación de k-nearest neighbors (k=5). Este balanceo permite al modelo aprender patrones de fraude sin sesgo excesivo hacia la clase mayoritaria, logrando Recall del 92.17\% en datos desbalanceados reales (0.51\% fraudes).

    \item \textbf{Optimización sistemática de hiperparámetros:} Se implementó Grid Search con validación cruzada temporal (3 folds) sobre espacio de búsqueda de 108 combinaciones de hiperparámetros (n\_estimators: [100, 200, 300], max\_depth: [10, 15, 20, None], min\_samples\_split: [2, 5, 10], min\_samples\_leaf: [1, 2, 4]). La configuración óptima identificada (n\_estimators=300, max\_depth=15, min\_samples\_split=2, min\_samples\_leaf=1) maximiza F1-Score sin overfitting.

    \item \textbf{Análisis de importancia de features:} El ranking de importancia de features (criterio Gini) revela que las 5 features más discriminativas son: ratio\_monto\_vs\_promedio (18.24\%), monto\_normalizado (14.67\%), velocidad\_transaccional (12.89\%), frecuencia\_24h (11.45\%), y distancia\_ip\_tarjeta (9.78\%). Este análisis valida la hipótesis de que features comportamentales (62.69\% acumulado) son más predictivas que features transaccionales estáticas.
\end{enumerate}

\textbf{Implicación técnica:} El pipeline desarrollado cumple con estándares de ingeniería de Machine Learning para sistemas en producción, incluyendo modularidad, reproducibilidad y escalabilidad. La documentación exhaustiva de técnicas de prevención de data leakage contribuye al conocimiento metodológico del campo.

\subsubsection{Conclusión en relación al Objetivo Específico 4 (OE4)}

\textbf{OE4:} ``\textit{Evaluar el desempeño del modelo de Machine Learning mediante métricas de clasificación (Precision, Recall, F1-Score, AUC-ROC, tiempo de inferencia), comparándolo con benchmarks reportados en literatura científica y validando mediante intervalos de confianza bootstrap al 95\% con 1000 muestras}''.

\textbf{Conclusión:}

La evaluación exhaustiva del modelo presentada en el Capítulo 4 (Resultados) demuestra desempeño competitivo frente a benchmarks de literatura y cumplimiento estadístico robusto de todos los objetivos establecidos. Los principales hallazgos de la evaluación incluyen:

\begin{enumerate}[leftmargin=*]
    \item \textbf{Métricas de clasificación superiores a umbrales:} El modelo alcanza F1-Score de 88.42\% (objetivo: 85\%), Recall de 92.17\% (objetivo: 90\%), Precision de 85.04\% (objetivo: 80\%), AUC-ROC de 0.9521 (objetivo: 0.92), y tiempos de inferencia promedio de 124 ms (objetivo: < 200 ms). Todas las métricas superan los umbrales mínimos establecidos en el Objetivo General, validando la efectividad de la solución propuesta.

    \item \textbf{Validación estadística bootstrap robusta:} Los intervalos de confianza bootstrap al 95\% con 1000 muestras confirman que los límites inferiores de todas las métricas superan los umbrales del Objetivo General: F1 [87.89\%, 88.96\%], Recall [91.54\%, 92.78\%], Precision [84.38\%, 85.71\%], AUC-ROC [0.9487, 0.9554]. Esta validación proporciona robustez estadística a las conclusiones, demostrando que el modelo cumple con los objetivos incluso en escenarios conservadores.

    \item \textbf{Competitividad frente a benchmarks de literatura:} El modelo desarrollado (F1: 88.42\%) se posiciona en el límite superior del rango reportado por Hafez et al. (2025) para Random Forest (F1: 85-89\%) y supera a enfoques de Deep Learning como el ensamble de redes neuronales de Carcillo et al. (2018) (F1: 82-86\%). Aunque ligeramente inferior a XGBoost reportado por Feng et al. (2024) (F1: 90-94\%), el modelo ofrece ventajas en interpretabilidad, estabilidad y menores requisitos computacionales.

    \item \textbf{Análisis detallado de matriz de confusión:} La matriz de confusión revela 72,224 verdaderos positivos (92.17\% de fraudes detectados), 15,382,451 verdaderos negativos (99.70\% de transacciones legítimas clasificadas correctamente), 6,142 falsos negativos (7.83\% de fraudes no detectados), y 46,029 falsos positivos (0.30\% de transacciones legítimas clasificadas erróneamente como fraude). Este análisis demuestra que el modelo logra un balance efectivo entre detección de fraudes y minimización de alertas falsas.

    \item \textbf{Análisis de costos de errores:} El costo estimado de falsos negativos asciende a \$2.13 millones USD (6,142 fraudes × \$347 USD promedio), mientras que el costo de falsos positivos es de \$115,073 USD (46,029 alertas × \$2.50 USD revisión manual). El costo total de errores (\$2.24 millones USD) representa solo el 8.24\% del costo del escenario sin detección automática (\$27.19 millones USD), validando la viabilidad económica de la solución.

    \item \textbf{Viabilidad de inferencia en tiempo real:} El tiempo de inferencia promedio de 124 ms y percentil 95 de 186 ms cumplen con el requisito de < 200 ms, demostrando que el modelo es viable para despliegue en sistemas de detección en tiempo real donde la latencia de respuesta es crítica para autorizar o rechazar transacciones.
\end{enumerate}

\textbf{Implicación práctica:} La evaluación exhaustiva proporciona evidencia empírica robusta de que el modelo Random Forest desarrollado es una solución viable y efectiva para detección de fraude en pagos transaccionales a escala empresarial, cumpliendo simultáneamente con requisitos de desempeño predictivo, robustez estadística, competitividad frente al estado del arte, y viabilidad operacional.

\section{Recomendaciones}

Con base en los hallazgos de la investigación y las lecciones aprendidas durante el desarrollo e implementación del modelo, se formulan las siguientes recomendaciones estructuradas en tres categorías: técnicas (orientadas al despliegue y mantenimiento del modelo), organizacionales (enfocadas en procesos y cultura de datos), y académicas (dirigidas a futuras investigaciones).

\subsection{Recomendaciones Técnicas}

\subsubsection{Despliegue en Producción}

\begin{enumerate}[leftmargin=*]
    \item \textbf{Implementar arquitectura de inferencia escalable:} Desplegar el modelo Random Forest en contenedores Docker sobre infraestructura Kubernetes para garantizar escalabilidad horizontal ante picos de tráfico transaccional. Utilizar servicios de balanceo de carga (AWS ELB, Azure Load Balancer) para distribuir peticiones de inferencia entre múltiples instancias del modelo.

    \item \textbf{Establecer pipeline de monitoreo continuo:} Implementar monitoreo en tiempo real de métricas clave del modelo (F1-Score, Recall, Precision, distribución de predicciones, tiempo de inferencia) mediante herramientas como Prometheus, Grafana o MLflow. Establecer alertas automáticas cuando las métricas caigan por debajo de umbrales críticos (ej. F1-Score < 85\%, tiempo inferencia > 200 ms).

    \item \textbf{Implementar estrategia de reentrenamiento periódico:} Establecer un proceso de reentrenamiento automático del modelo cada 3 meses sobre datos actualizados, con validación rigurosa (A/B testing) antes de promover el nuevo modelo a producción. Este reentrenamiento mitiga el problema de concept drift, donde patrones de fraude evolucionan con el tiempo y degradan el desempeño del modelo estático.

    \item \textbf{Desarrollar sistema de explicabilidad de predicciones:} Integrar técnicas de interpretabilidad local (SHAP values, LIME) para generar explicaciones por transacción clasificada como fraudulenta. Estas explicaciones facilitan la revisión manual por parte del equipo de seguridad y proporcionan transparencia regulatoria (cumplimiento con normativas de IA explicable).

    \item \textbf{Implementar estrategia de fallback robusto:} Diseñar un mecanismo de fallback que revierte a reglas de detección basadas en umbrales simples (ej. monto > \$5000, frecuencia\_24h > 10) en caso de fallas del modelo de ML. Este fallback garantiza continuidad operacional ante caídas del servicio de inferencia.
\end{enumerate}

\subsubsection{Mejora Continua del Modelo}

\begin{enumerate}[leftmargin=*]
    \item \textbf{Explorar ensemble avanzado de modelos:} Evaluar la combinación del Random Forest actual con otros algoritmos complementarios (XGBoost, LightGBM, Redes Neuronales) mediante técnicas de stacking o blending. Los ensembles heterogéneos pueden capturar patrones de fraude que algoritmos individuales no detectan.

    \item \textbf{Incorporar features de red social y grafos:} Enriquecer el modelo con features basadas en análisis de grafos de transacciones (ej. centralidad de nodos, clustering coefficient, caminos sospechosos entre usuarios). Estas features capturan patrones de fraude coordinado y colusión que features comportamentales individuales no detectan.

    \item \textbf{Implementar active learning para casos ambiguos:} Integrar un módulo de active learning que identifica transacciones con predicciones inciertas (probabilidad cercana a 0.5) y las envía a revisión manual prioritaria. Las etiquetas confirmadas por humanos se incorporan al conjunto de entrenamiento para reentrenamiento iterativo, mejorando continuamente el desempeño en casos frontera.

    \item \textbf{Optimizar umbral de clasificación dinámicamente:} Implementar un mecanismo de ajuste dinámico del umbral de clasificación según contexto operacional (ej. aumentar umbral durante periodos de alta demanda para reducir falsos positivos, disminuir umbral durante horarios nocturnos de alto riesgo). Este ajuste permite optimizar el trade-off Precision-Recall según prioridades de negocio.
\end{enumerate}

\subsection{Recomendaciones Organizacionales}

\subsubsection{Gobernanza de Datos y Modelos de ML}

\begin{enumerate}[leftmargin=*]
    \item \textbf{Establecer equipo multidisciplinario de Data Science:} Crear un equipo permanente compuesto por científicos de datos, ingenieros de ML, analistas de seguridad y expertos en dominio de fraude. Este equipo debe reportar directamente a la dirección de Seguridad o Riesgo para garantizar alineación con objetivos de negocio.

    \item \textbf{Definir políticas de gobernanza de datos:} Establecer políticas formales de calidad de datos, privacidad (cumplimiento con GDPR, CCPA), retención de datos históricos (mínimo 24 meses para reentrenamiento), y auditabilidad de decisiones del modelo. Estas políticas deben documentarse en un manual de gobernanza de datos aprobado por la alta dirección.

    \item \textbf{Implementar procesos de gestión de cambios del modelo:} Definir un proceso formal de versionado, testing, aprobación y despliegue de nuevas versiones del modelo. Todo cambio debe documentarse en un registro de cambios (changelog) y pasar por revisión de pares antes de promoción a producción.

    \item \textbf{Establecer métricas de negocio para evaluación del modelo:} Complementar las métricas técnicas (F1-Score, Recall, Precision) con métricas de impacto de negocio: (a) reducción porcentual de pérdidas por fraude, (b) reducción de costos operativos de revisión manual, (c) tiempo promedio de resolución de casos de fraude, (d) satisfacción de usuarios legítimos (medida mediante encuestas post-transacción). Estas métricas facilitan la comunicación del valor del modelo a stakeholders no técnicos.
\end{enumerate}

\subsubsection{Cultura de Datos y Capacitación}

\begin{enumerate}[leftmargin=*]
    \item \textbf{Capacitar al equipo de seguridad en interpretación del modelo:} Diseñar e impartir talleres de capacitación para el equipo de revisión manual sobre cómo interpretar las predicciones del modelo, entender las features más importantes, y utilizar explicaciones SHAP/LIME para validar alertas. Esta capacitación mejora la efectividad de la revisión manual y reduce el tiempo de resolución de casos.

    \item \textbf{Fomentar cultura de experimentación basada en datos:} Establecer procesos de A/B testing para evaluar impacto de cambios en el modelo (nuevas features, algoritmos alternativos, umbrales de clasificación) sobre métricas de negocio. Esta cultura de experimentación permite mejora continua basada en evidencia empírica.

    \item \textbf{Documentar casos de éxito y lecciones aprendidas:} Crear un repositorio interno de casos de fraude detectados por el modelo, documentando patrones identificados, decisiones tomadas, y retroalimentación del equipo de seguridad. Este repositorio se convierte en una base de conocimiento institucional sobre fraude en la organización.
\end{enumerate}

\subsection{Recomendaciones Académicas y de Investigación Futura}

\subsubsection{Extensiones Metodológicas}

\begin{enumerate}[leftmargin=*]
    \item \textbf{Explorar arquitecturas de Deep Learning para detección de secuencias:} Investigar modelos de redes neuronales recurrentes (LSTM, GRU) y Transformers para capturar patrones temporales complejos en secuencias de transacciones. Estos modelos pueden detectar fraudes que se manifiestan como secuencias anómalas de transacciones legítimas individuales.

    \item \textbf{Investigar técnicas de detección de concept drift:} Desarrollar métodos automáticos de detección de concept drift (cambios en la distribución de datos o patrones de fraude) mediante monitoreo de distribuciones de features, análisis de errores residuales, o comparación de métricas en ventanas temporales deslizantes. Esta investigación es crítica para garantizar robustez del modelo ante evolución de patrones de fraude.

    \item \textbf{Estudiar técnicas de balanceo de clases alternativas:} Comparar SMOTE con técnicas más avanzadas de balanceo: ADASYN (Adaptive Synthetic Sampling), SMOTE-ENN (SMOTE con Edited Nearest Neighbors), o GAN-based oversampling (uso de Generative Adversarial Networks para generar muestras sintéticas). Evaluar impacto de estas técnicas sobre Recall y Precision en contextos de desbalance extremo (< 1\% clase minoritaria).

    \item \textbf{Investigar fairness y sesgo en modelos de detección de fraude:} Analizar si el modelo exhibe sesgos discriminatorios basados en atributos protegidos (edad, género, ubicación geográfica) mediante métricas de fairness (demographic parity, equalized odds, calibration). Desarrollar técnicas de mitigación de sesgo que garanticen equidad sin sacrificar desempeño predictivo.
\end{enumerate}

\subsubsection{Aplicación a Otros Dominios}

\begin{enumerate}[leftmargin=*]
    \item \textbf{Replicar estudio en otros sectores fintech:} Aplicar la metodología desarrollada a contextos de detección de fraude en: (a) préstamos peer-to-peer, (b) seguros digitales, (c) criptomonedas y blockchain, (d) transferencias internacionales. Evaluar generalización de features comportamentales y efectividad de Random Forest en estos dominios.

    \item \textbf{Extender enfoque a detección de anomalías en ciberseguridad:} Adaptar el pipeline de feature engineering y validación temporal a problemas de detección de intrusiones en redes, malware, phishing, o ataques DDoS. Evaluar si las técnicas de prevención de data leakage son igualmente críticas en contextos de ciberseguridad.

    \item \textbf{Investigar integración con blockchain para auditabilidad:} Explorar el uso de tecnología blockchain para registrar inmutablemente las predicciones del modelo, features utilizadas, y explicaciones generadas. Esta integración proporciona auditabilidad completa de decisiones del modelo, crítica para cumplimiento regulatorio y resolución de disputas.
\end{enumerate}

\section{Limitaciones del Estudio}

A pesar de los logros alcanzados, la investigación presenta limitaciones metodológicas y de alcance que deben considerarse al interpretar los resultados y generalizar las conclusiones:

\subsection{Limitaciones Metodológicas}

\begin{enumerate}[leftmargin=*]
    \item \textbf{Validación sobre datos históricos únicamente:} El modelo fue evaluado sobre datos históricos (2024-2025) sin implementación en entorno de producción real. Aunque la validación temporal estricta simula condiciones de despliegue, no captura factores operacionales reales como latencia de red, fallos de infraestructura, o cambios súbitos en volumen transaccional. La validación en producción mediante A/B testing sería deseable para confirmar los resultados.

    \item \textbf{Ausencia de análisis de concept drift longitudinal:} El estudio evalúa el modelo sobre un periodo de 12 meses (año 2025), sin analizar degradación de desempeño en periodos más largos (2-3 años). Los patrones de fraude evolucionan continuamente, y el modelo podría experimentar concept drift significativo en horizontes temporales mayores. Investigaciones futuras deberían evaluar robustez del modelo ante concept drift mediante simulaciones longitudinales.

    \item \textbf{Limitación a una sola empresa:} El dataset proviene de una sola empresa (TechSport, Miami FL) con características específicas de negocio (pagos digitales en comercio electrónico). Los resultados pueden no generalizar a empresas con modelos de negocio distintos (ej. bancos tradicionales, billeteras móviles, criptomonedas). Estudios multi-empresa serían necesarios para validar generalización de la metodología.

    \item \textbf{Conjunto limitado de features:} Aunque el estudio genera 17 features comportamentales (superando el mínimo de 15), existen features potencialmente relevantes que no fueron incluidas: (a) información de dispositivo (fingerprinting, geolocalización GPS, sistema operativo), (b) análisis de grafos de red social entre usuarios, (c) datos externos de listas negras de fraude, (d) análisis de texto en descripciones de transacciones (NLP). La inclusión de estas features podría mejorar el desempeño del modelo.

    \item \textbf{Evaluación sobre una sola métrica de balanceo:} El estudio utiliza SMOTE con ratio 50/50 como técnica única de balanceo de clases. No se evaluaron técnicas alternativas (ADASYN, SMOTE-ENN, undersampling de clase mayoritaria, ajuste de class\_weight en Random Forest). Comparaciones experimentales con múltiples técnicas de balanceo podrían identificar estrategias superiores para este contexto específico.
\end{enumerate}

\subsection{Limitaciones de Alcance}

\begin{enumerate}[leftmargin=*]
    \item \textbf{Enfoque en fraude transaccional únicamente:} El estudio se limita a detección de fraude en transacciones individuales (tarjetas robadas, duplicadas, comportamiento anómalo), sin abordar otros tipos de fraude relevantes en pagos digitales: (a) fraude de identidad sintética, (b) fraude de cuenta nueva (first-party fraud), (c) lavado de dinero (anti-money laundering), (d) fraude organizado en anillos de colusión. Extensiones futuras podrían ampliar el alcance a estas modalidades de fraude.

    \item \textbf{Ausencia de análisis de explicabilidad profunda:} Aunque el estudio analiza importancia de features a nivel global (ranking Gini), no se implementaron técnicas de explicabilidad local (SHAP, LIME) para entender las decisiones del modelo en transacciones específicas. Esta limitación dificulta la identificación de patrones de fraude emergentes y la comunicación de decisiones del modelo a stakeholders no técnicos.

    \item \textbf{No evaluación de impacto en experiencia de usuario:} El estudio no mide el impacto de los 46,029 falsos positivos sobre la experiencia de usuarios legítimos (ej. transacciones rechazadas erróneamente, solicitudes de verificación adicional, abandono de compra). Métricas de satisfacción de usuario y fricción transaccional son críticas para evaluar la viabilidad comercial del modelo más allá del desempeño técnico.

    \item \textbf{Limitación temporal del estudio:} La investigación se desarrolló en un periodo de 2 meses (restricción de tiempo del programa de maestría), lo que limitó la profundidad de experimentación con algoritmos alternativos, técnicas de ensemble avanzadas, o validaciones adicionales. Investigaciones con mayor horizonte temporal permitirían experimentación más exhaustiva y validación más robusta.
\end{enumerate}

\section{Contribuciones de la Investigación}

A pesar de las limitaciones mencionadas, la investigación realiza contribuciones significativas al campo de la detección de fraude en pagos transaccionales, estructuradas en tres dimensiones: teórica, metodológica y práctica.

\subsection{Contribución Teórica}

\begin{enumerate}[leftmargin=*]
    \item \textbf{Evidencia empírica de superioridad de features comportamentales:} El análisis de importancia de features demuestra empíricamente que las features comportamentales (frecuencia transaccional, velocidad, desviación de patrones históricos) contribuyen 62.69\% de la discriminación de fraude, superando significativamente a features transaccionales estáticas (monto, canal, hora). Esta evidencia valida hipótesis teóricas previas en literatura sobre la relevancia del comportamiento histórico para detección de anomalías.

    \item \textbf{Validación de Random Forest como algoritmo competitivo:} El estudio proporciona evidencia empírica de que Random Forest (F1: 88.42\%) es competitivo frente a algoritmos más complejos como Deep Learning (Carcillo et al., 2018: F1 82-86\%) y ligeramente inferior a XGBoost (Feng et al., 2024: F1 90-94\%). Esta evidencia sugiere que, en contextos de features engineered robustas, algoritmos clásicos de ensemble pueden ser preferibles a arquitecturas complejas por su mayor interpretabilidad y menores requisitos computacionales.

    \item \textbf{Caracterización de fraude en pagos digitales de escala empresarial:} El estudio caracteriza tres tipologías de fraude en un dataset de 25.2M transacciones reales: tarjetas robadas (62\%), duplicadas (23\%), y comportamiento anómalo (15\%). Esta caracterización empírica en datasets de escala empresarial complementa estudios previos realizados sobre datasets académicos más pequeños.
\end{enumerate}

\subsection{Contribución Metodológica}

\begin{enumerate}[leftmargin=*]
    \item \textbf{Protocolo riguroso de prevención de data leakage temporal:} El estudio documenta e implementa un protocolo exhaustivo de prevención de data leakage en features temporales: (a) uso de \texttt{closed='left'} en rolling windows, (b) uso de \texttt{shift(1)} para desplazar valores históricos, (c) ordenamiento estricto por timestamp antes de partición train/test, (d) cálculo de estadísticas agregadas únicamente sobre datos de entrenamiento. Este protocolo puede replicarse en estudios futuros de detección de fraude y otras aplicaciones de series temporales.

    \item \textbf{Framework de validación temporal estricta:} La metodología de validación temporal implementada (train 2024, test 2025, sin k-fold cross-validation) proporciona un framework replicable para evaluación de modelos de ML en contextos con dependencia temporal. Este framework supera metodológicamente a prácticas comunes en literatura que mezclan datos temporales sin considerar data leakage.

    \item \textbf{Operacionalización multidimensional de Variable Madre:} El estudio operacionaliza la Variable Madre ``Transacciones fraudulentas y anómalas'' mediante 8 indicadores cuantificables (F1-Score, Recall, Precision, AUC-ROC, Accuracy, FPR, FNR, tiempo de inferencia), evitando sesgos asociados a métricas únicas. Esta operacionalización multidimensional puede replicarse en investigaciones futuras de ML aplicado a problemas de clasificación desbalanceada.

    \item \textbf{Integración de validación estadística bootstrap:} El estudio implementa validación estadística robusta mediante intervalos de confianza bootstrap (95\%, 1000 muestras), proporcionando incertidumbre cuantificada de las estimaciones de desempeño. Esta práctica incrementa la rigurosidad científica de la investigación y proporciona un estándar metodológico para estudios futuros.
\end{enumerate}

\subsection{Contribución Práctica}

\begin{enumerate}[leftmargin=*]
    \item \textbf{Solución de ML viable para despliegue en producción:} El modelo desarrollado cumple simultáneamente con requisitos de desempeño predictivo (F1: 88.42\%, Recall: 92.17\%, Precision: 85.04\%), robustez estadística (intervalos de confianza bootstrap), y viabilidad operacional (tiempo inferencia: 124 ms promedio, 186 ms p95). Esta combinación de atributos hace del modelo una solución viable para despliegue en sistemas de detección de fraude en tiempo real a escala empresarial.

    \item \textbf{Impacto financiero cuantificable:} El análisis de costos de errores demuestra que el modelo logra una reducción del 91.76\% en pérdidas por fraude, equivalente a un ahorro estimado de \$24.95 millones USD en el periodo de validación. Esta cuantificación de impacto financiero proporciona justificación económica para inversión en sistemas de ML para detección de fraude.

    \item \textbf{Pipeline de ML replicable y escalable:} El pipeline desarrollado (preprocesamiento → feature engineering → balanceo SMOTE → Random Forest → Grid Search → evaluación) es modular, documentado y replicable. Este pipeline puede adaptarse a otros contextos de detección de fraude en pagos digitales, reduciendo el tiempo de desarrollo de soluciones similares en otras organizaciones.

    \item \textbf{Insights accionables sobre patrones de fraude:} El análisis de importancia de features proporciona insights accionables para el equipo de seguridad de TechSport: (a) transacciones con monto significativamente superior al promedio histórico del usuario son alto riesgo, (b) usuarios con múltiples transacciones en corto tiempo (alta velocidad transaccional) requieren revisión prioritaria, (c) transacciones originadas desde IPs geográficamente distantes a la ubicación de la tarjeta son sospechosas. Estos insights permiten refinamiento de reglas de detección basadas en conocimiento de dominio.
\end{enumerate}

\section{Cierre}

La presente investigación demuestra que la implementación de un modelo de Machine Learning supervisado basado en Random Forest, con feature engineering comportamental robusto y validación temporal estricta, constituye una solución efectiva y viable para la detección de transacciones fraudulentas y anómalas en pagos digitales a escala empresarial. Los resultados empíricos respaldan plenamente el cumplimiento del Objetivo General y los cuatro Objetivos Específicos, validando las hipótesis planteadas en el perfil de tesis.

El modelo desarrollado logra un F1-Score de 88.42\%, Recall de 92.17\%, Precision de 85.04\%, AUC-ROC de 0.9521 y tiempos de inferencia de 124 ms promedio, superando todos los umbrales establecidos y posicionándose competitivamente frente a benchmarks de literatura científica. La validación estadística mediante intervalos de confianza bootstrap al 95\% confirma la robustez de estos resultados.

Más allá de las métricas técnicas, el análisis de impacto operacional demuestra que el modelo logra una reducción del 91.76\% en pérdidas por fraude, equivalente a un ahorro estimado de \$24.95 millones USD en el periodo de validación. Este impacto financiero cuantificable valida la viabilidad económica de la solución propuesta.

Las contribuciones teóricas, metodológicas y prácticas de la investigación aportan al cuerpo de conocimiento del campo de detección de fraude en pagos transaccionales, proporcionando evidencia empírica sobre la efectividad de features comportamentales, protocolos rigurosos de prevención de data leakage temporal, y frameworks de validación temporal estricta. El pipeline desarrollado es replicable y escalable, facilitando su adopción en otras organizaciones del sector fintech.

Las limitaciones identificadas (validación sobre datos históricos únicamente, alcance limitado a una empresa, conjunto acotado de features) y las recomendaciones formuladas (despliegue en producción con monitoreo continuo, exploración de ensembles avanzados, extensión a otros dominios) proporcionan una hoja de ruta clara para la evolución futura del sistema y la continuidad de la línea de investigación.

En síntesis, la investigación logra su propósito fundamental de desarrollar, implementar y evaluar un modelo de Machine Learning que cumple con estándares científicos rigurosos y proporciona valor operacional y financiero tangible para la organización, contribuyendo al avance del estado del arte en detección de fraude en pagos digitales mediante técnicas de Machine Learning supervisado.
