% ==================================================================================
% CAPÍTULO 1: MARCO TEÓRICO CONCEPTUAL
% ==================================================================================
% Estructura según Sampieri (2018): Antecedentes, Bases Teóricas, Definición de Términos
% Triangulación: PE1 → OE1 → HE1
% ==================================================================================

\chapter{Marco Teórico Conceptual}

El presente capítulo desarrolla la fundamentación teórica que sustenta la investigación, respondiendo al Problema Específico 1 (PE1): \textit{¿Cuál es el fundamento teórico-técnico que respalda el uso de modelos de Machine Learning supervisados, particularmente Random Forest, para la detección de fraude en pagos digitales según la literatura científica 2020-2025?}

Según \textcite[p. 60]{Hernandez2018}, el marco teórico cumple funciones esenciales: proporciona un conocimiento profundo de la teoría que da significado a la investigación, permite al investigador establecer hipótesis y conducir al establecimiento de afirmaciones que más tarde habrán de someterse a prueba. En este sentido, el capítulo se estructura en tres componentes: antecedentes de la investigación, bases teóricas y definición de términos básicos.

% ==================================================================================
% 1.1. ANTECEDENTES DE LA INVESTIGACIÓN
% ==================================================================================

\section{Antecedentes de la Investigación}

Los antecedentes constituyen estudios previos relacionados con el problema de investigación. Según \textcite[p. 68]{Hernandez2018}, estos permiten conocer qué se ha hecho hasta el momento en relación con el tema de estudio, identificar enfoques metodológicos aplicados y reconocer brechas de conocimiento. A continuación se presentan investigaciones relevantes del periodo 2020-2025 sobre detección de fraude mediante Machine Learning.

\subsection{Antecedentes Internacionales}

\textcite{Hafez2025} realizaron una revisión sistemática de 87 estudios sobre detección de fraude con tarjetas de crédito mediante inteligencia artificial. Los autores analizaron publicaciones de las bases de datos IEEE Xplore, Springer, Wiley y Journal of Big Data. Los resultados evidenciaron que Random Forest alcanza F1-Scores entre 85\% y 89\%, con Recall de 87-92\%. El estudio concluye que los métodos de ensemble learning constituyen el enfoque dominante en la literatura reciente, superando a técnicas tradicionales basadas en reglas estáticas.

\textcite{HernandezAros2024} desarrollaron una revisión de técnicas de Machine Learning aplicadas a fraude financiero. Su investigación abarcó estudios publicados entre 2019 y 2024, identificando que los enfoques híbridos de ensemble (combinación de Random Forest con XGBoost) logran F1-Scores de 91-95\% y Recall de 93-97\%. Los autores enfatizan la importancia del feature engineering y la validación temporal para garantizar la generalización de los modelos.

\textcite{Feng2024} implementaron Random Forest y XGBoost en un dataset de transacciones con tarjetas de crédito. Su estudio reportó F1-Score de 90-94\% para XGBoost y 85-89\% para Random Forest, con AUC-ROC de 0,96 y 0,93 respectivamente. Los investigadores concluyeron que XGBoost ofrece una ventaja marginal a costa de tres veces mayor tiempo de entrenamiento, lo que posiciona a Random Forest como alternativa viable cuando se requiere balance entre desempeño e interpretabilidad.

\textcite{AlEmad2022} compararon Random Forest, SVM y KNN en detección de fraude financiero. Los resultados mostraron que Random Forest logra F1-Score de 87\%, superando a SVM (82-85\%) y KNN (78\%). Los autores destacan la superioridad de Random Forest en interpretabilidad y robustez ante datos desbalanceados, características relevantes para aplicaciones en contextos regulados.

\textcite{Grinsztajn2022} realizaron un estudio comparativo entre modelos basados en árboles (Random Forest, XGBoost) y deep learning (ResNet, FT-Transformer) en 45 datasets tabulares. Los resultados demostraron que los tree-based models superan a deep learning en datos tabulares típicos, con diferencias estadísticamente significativas (p < 0,01). Este hallazgo fundamenta la selección de Random Forest para datos transaccionales estructurados.

\textcite{Carcillo2018} desarrollaron un framework escalable de detección de fraude utilizando Apache Spark. Su implementación de Random Forest distribuido procesó más de 100 millones de transacciones con latencia inferior a 200 milisegundos. El estudio valida la viabilidad de despliegue en producción para datasets masivos, aspecto relevante considerando el volumen de 15,6 millones de transacciones de TechSport.

\subsection{Antecedentes Regionales y Latinoamericanos}

\textcite{Lucas2019} desarrolló en su tesis doctoral (INSA Lyon, Francia) un sistema de detección de fraude con integración de conocimiento contextual. El autor construyó más de 50 features comportamentales y logró F1-Score de 92\% con Random Forest. Su trabajo proporciona fundamento metodológico para el feature engineering aplicable a esta investigación.

\textcite{Chaquet2022} en su tesis doctoral (Universidad Rey Juan Carlos, España) investigó Machine Learning interpretable para fraude crediticio. Los resultados mostraron F1-Score de 89\% con Random Forest. El estudio enfatiza la importancia de la interpretabilidad para cumplimiento regulatorio bajo GDPR y PCI DSS.

\textcite{Rayo2020} desarrolló en su tesis de maestría (Universidad de Lima, Perú) un prototipo de detección de fraude con Random Forest para una entidad bancaria peruana. El modelo alcanzó F1-Score de 87\% y Recall de 91\%. Este antecedente resulta relevante por su contexto latinoamericano, similar al entorno operativo de TechSport en la región.

\textcite{Perez2021} en su tesis de maestría (Universidad de los Andes, Colombia) implementó detección de fraude en tarjetas de crédito mediante Machine Learning. Random Forest logró F1-Score de 85\%, validando la viabilidad del enfoque en contextos financieros latinoamericanos con características similares a las de TechSport.

\subsection{Síntesis de Antecedentes}

La revisión de antecedentes evidencia convergencia en los siguientes aspectos:

\begin{enumerate}
    \item Random Forest alcanza consistentemente F1-Scores entre 85\% y 92\% en detección de fraude financiero.

    \item Los métodos de ensemble learning superan a técnicas tradicionales basadas en reglas estáticas.

    \item La interpretabilidad de Random Forest facilita el cumplimiento de requisitos regulatorios (PCI DSS, GDPR).

    \item El feature engineering comportamental incrementa significativamente el desempeño predictivo.

    \item La validación temporal es imprescindible para garantizar generalización en contextos financieros.

    \item Existen implementaciones exitosas en contextos latinoamericanos con características similares a TechSport.
\end{enumerate}

% ==================================================================================
% 1.2. BASES TEÓRICAS
% ==================================================================================

\section{Bases Teóricas}

Las bases teóricas constituyen el conjunto de proposiciones y conceptos que fundamentan la investigación. Según \textcite[p. 72]{Hernandez2018}, estas permiten explicar, comprender y predecir el fenómeno estudiado. A continuación se desarrollan los fundamentos teóricos de la detección de fraude mediante Machine Learning.

\subsection{Fraude en Pagos Digitales}

\subsubsection{Conceptualización del Fraude Financiero}

El fraude en pagos digitales se define como cualquier actividad ilegal o deshonesta que busca obtener beneficios económicos mediante el engaño, la manipulación o el abuso de sistemas de pago electrónicos \parencite{Baesens2015}. En el contexto de transacciones digitales, esta definición abarca el uso no autorizado de instrumentos de pago, la suplantación de identidad y la explotación de vulnerabilidades tecnológicas.

\textcite{HernandezAros2024} categorizan el fraude financiero en tres familias principales: fraude con tarjetas de crédito/débito, fraude en transacciones bancarias y fraude en sistemas de pago electrónico. Para el ámbito de pagos transaccionales digitales, se identifican las siguientes tipologías:

\begin{enumerate}
    \item \textbf{Fraude por tarjeta robada o clonada:} Uso no autorizado de credenciales de pago obtenidas mediante robo físico, phishing o técnicas de skimming. Representa aproximadamente el 60\% de los casos en plataformas de comercio electrónico \parencite{Hafez2025}.

    \item \textbf{Transacciones duplicadas sospechosas:} Múltiples intentos de cargo sobre el mismo instrumento de pago en periodos cortos, generalmente asociados a pruebas de validez de tarjetas robadas. \textcite{Lucas2019} documenta que el 15-20\% de fraudes involucran patrones de transacciones de alta frecuencia.

    \item \textbf{Comportamientos anómalos de usuarios:} Patrones transaccionales que se desvían del comportamiento histórico del usuario legítimo, como cambios abruptos en montos, frecuencia o geolocalización \parencite{Baesens2015}.

    \item \textbf{Fraude de identidad sintética:} Creación de identidades ficticias mediante combinación de información real y falsa para establecer perfiles de pago fraudulentos \parencite{Feng2024}.
\end{enumerate}

\subsubsection{Impacto Económico del Fraude Digital}

El impacto del fraude en pagos digitales trasciende las pérdidas económicas directas. \textcite{OEABID2020} documentan que en América Latina el fraude digital genera:

\begin{itemize}
    \item \textbf{Pérdidas económicas directas:} Valores monetarios sustraídos que representan en promedio el 1,5\% del volumen total de transacciones digitales en la región.

    \item \textbf{Costos operativos:} Recursos destinados a investigación de disputas y chargebacks, estimados en 3 a 5 veces el valor de la transacción fraudulenta \parencite{Baesens2015}.

    \item \textbf{Deterioro reputacional:} Pérdida de confianza que puede reducir la retención de clientes entre 20\% y 30\% según estudios de comportamiento del consumidor \parencite{Lucas2019}.

    \item \textbf{Sanciones regulatorias:} Multas por incumplimiento de normativas como PCI DSS que pueden alcanzar montos significativos y restricciones operativas.
\end{itemize}

\subsubsection{Limitaciones de los Sistemas Basados en Reglas Estáticas}

Los sistemas tradicionales de detección de fraude operan mediante reglas determinísticas predefinidas. Según \textcite{Baesens2015}, estos sistemas funcionan con umbrales fijos y condiciones booleanas como:

\begin{itemize}
    \item Si monto $>$ \$500 USD y país IP $\neq$ país tarjeta $\Rightarrow$ Rechazar
    \item Si frecuencia transaccional $>$ 5 transacciones/hora $\Rightarrow$ Alerta
    \item Si categoría comerciante = ``alto riesgo'' $\Rightarrow$ Revisión manual
\end{itemize}

\textcite{Rodriguez2023} y \textcite{HernandezAros2024} identifican limitaciones estructurales que motivan la adopción de Machine Learning:

\begin{enumerate}
    \item \textbf{Ausencia de capacidad de aprendizaje:} Las reglas permanecen estáticas y no se adaptan a nuevos patrones. \textcite{Hafez2025} documentan que el tiempo promedio de actualización de reglas es de 3-6 semanas, periodo durante el cual el sistema queda vulnerable.

    \item \textbf{Alta tasa de falsos positivos:} Reglas conservadoras rechazan transacciones legítimas, generando tasas de falsos positivos del 10-15\% \parencite{Baesens2015}.

    \item \textbf{Mantenimiento intensivo:} La actualización requiere intervención constante de expertos, con costos operativos que representan 2-3 veces el costo de desarrollo inicial \parencite{Feng2024}.

    \item \textbf{Imposibilidad de correlaciones multidimensionales:} Las reglas simples no capturan interacciones complejas entre múltiples variables \parencite{Geron2022}.

    \item \textbf{Degradación temporal:} El desempeño se degrada 15-20\% anualmente debido a la evolución de patrones de fraude (concept drift) \parencite{Murphy2022}.
\end{enumerate}

\subsection{Machine Learning Supervisado}

\subsubsection{Fundamentos del Aprendizaje Supervisado}

El aprendizaje automático supervisado constituye un paradigma computacional en el cual un algoritmo aprende a mapear entradas (features) a salidas (etiquetas) mediante el análisis de datos históricos etiquetados \parencite{James2021}. En detección de fraude, esto implica entrenar modelos con transacciones previamente clasificadas como fraudulentas o legítimas para predecir la naturaleza de transacciones futuras.

\textcite{Geron2022} formaliza el problema de clasificación supervisada como la búsqueda de una función $f: \mathcal{X} \rightarrow \mathcal{Y}$ que minimiza una función de pérdida $\mathcal{L}$ sobre un conjunto de entrenamiento $D = \{(x_i, y_i)\}_{i=1}^{n}$, donde:

\begin{itemize}
    \item $x_i \in \mathcal{X}$ representa el vector de features de la transacción $i$
    \item $y_i \in \{0, 1\}$ indica si la transacción es legítima (0) o fraudulenta (1)
    \item $f(x_i) \in [0,1]$ es la probabilidad estimada de que la transacción sea fraudulenta
\end{itemize}

El proceso de entrenamiento busca minimizar:

\begin{equation}
    \min_{f \in \mathcal{F}} \sum_{i=1}^{n} \mathcal{L}(y_i, f(x_i)) + \lambda \Omega(f)
\end{equation}

donde $\mathcal{L}$ es la función de pérdida (típicamente binary cross-entropy), $\Omega(f)$ es un término de regularización y $\lambda$ controla el trade-off entre ajuste y complejidad.

\subsubsection{Random Forest: Algoritmo de Ensemble Learning}

Random Forest es un método de ensemble que construye múltiples árboles de decisión durante el entrenamiento y produce la clase modal de las predicciones individuales \parencite{Breiman2001}. El algoritmo presenta características específicas que lo posicionan como adecuado para detección de fraude:

\textbf{Interpretabilidad:} Permite calcular la importancia de cada feature mediante el decremento promedio de impureza (Gini) o mediante permutación, facilitando auditorías y cumplimiento regulatorio \parencite{Hafez2025}.

\textbf{Robustez ante overfitting:} La agregación de múltiples árboles mediante bagging reduce la varianza del modelo. \textcite{Breiman2001} demuestran que Random Forest converge a un error generalizable conforme aumenta el número de árboles.

\textbf{Manejo de variables mixtas:} Procesa features categóricas y numéricas directamente, simplificando el preprocesamiento a diferencia de SVM o redes neuronales \parencite{Geron2022}.

\textbf{Resistencia a outliers:} La naturaleza basada en splits reduce el impacto de valores extremos, relevante para transacciones con montos atípicos \parencite{Hastie2009}.

\textbf{Escalabilidad:} El entrenamiento es paralelizable (cada árbol se entrena independientemente), viable para datasets de millones de transacciones \parencite{Pedregosa2011}.

\textbf{Manejo de desbalanceo:} Soporta class weights nativamente mediante el parámetro \texttt{class\_weight='balanced'} \parencite{Pedregosa2011}.

La formalización matemática del algoritmo construye $B$ árboles de decisión $\{T_b\}_{b=1}^{B}$ mediante bootstrap sampling. La predicción se obtiene por votación mayoritaria:

\begin{equation}
    \hat{y} = \text{mode}\left(\{T_1(x), T_2(x), \ldots, T_B(x)\}\right)
\end{equation}

Para clasificación probabilística:

\begin{equation}
    P(\text{fraude} | x) = \frac{1}{B} \sum_{b=1}^{B} \mathbb{1}(T_b(x) = \text{fraude})
\end{equation}

\subsubsection{Algoritmos Comparativos}

\textbf{Gradient Boosting (XGBoost, LightGBM):} Construye árboles secuencialmente donde cada árbol corrige errores del anterior \parencite{Geron2022}. \textcite{Feng2024} reportan F1-Scores de 90-95\%, superiores a Random Forest, pero con 3-4 veces mayor tiempo de entrenamiento y menor interpretabilidad.

\textbf{Support Vector Machines:} Busca el hiperplano óptimo que maximiza el margen entre clases \parencite{James2021}. Su complejidad $O(n^2)$ o $O(n^3)$ lo hace inviable para datasets de millones de transacciones. \textcite{AlEmad2022} reportan F1-Score de 82-85\%, inferior a Random Forest.

\textbf{Redes Neuronales Profundas:} \textcite{Grinsztajn2022} demuestran que para datos tabulares, los modelos basados en árboles superan consistentemente a deep learning, con diferencias estadísticamente significativas. Las redes neuronales además presentan limitaciones de interpretabilidad incompatibles con requisitos regulatorios.

\subsection{Métricas de Evaluación en Contextos Desbalanceados}

La evaluación de modelos de detección de fraude requiere métricas especializadas debido al desbalanceo inherente de las clases (típicamente $<$5\% de transacciones fraudulentas). \textcite{Geron2022} enfatizan que accuracy es inadecuada, ya que un clasificador que predice siempre ``legítimo'' alcanzaría 95-99\% de accuracy siendo completamente inútil.

\subsubsection{Matriz de Confusión}

La matriz de confusión descompone las predicciones en cuatro categorías:

\begin{table}[H]
\centering
\caption{Matriz de Confusión para Clasificación Binaria}
\label{tab:confusion_matrix}
\begin{tabular}{@{}lcc@{}}
\toprule
& \textbf{Predicción: Fraude} & \textbf{Predicción: Legítimo} \\
\midrule
\textbf{Real: Fraude} & Verdadero Positivo (VP) & Falso Negativo (FN) \\
\textbf{Real: Legítimo} & Falso Positivo (FP) & Verdadero Negativo (VN) \\
\bottomrule
\end{tabular}
\end{table}

En detección de fraude: VP representa fraudes detectados (pérdidas evitadas), FN representa fraudes no detectados (pérdidas consumadas), FP representa transacciones legítimas bloqueadas (fricción con usuarios), y VN representa transacciones legítimas aprobadas correctamente.

\subsubsection{Precision, Recall y F1-Score}

\textbf{Precision} mide la proporción de predicciones positivas correctas:

\begin{equation}
    \text{Precision} = \frac{VP}{VP + FP}
\end{equation}

Una Precision alta indica pocos falsos positivos. Según \textcite{Lucas2019}, cada FP puede costar 5-10 veces más que el procesamiento de una transacción legítima debido a gestión de disputas y pérdida de clientes.

\textbf{Recall (Sensibilidad)} mide la proporción de fraudes reales detectados:

\begin{equation}
    \text{Recall} = \frac{VP}{VP + FN}
\end{equation}

En detección de fraude, Recall es prioritario porque los FN representan pérdidas económicas directas \parencite{Baesens2015}.

\textbf{F1-Score} es la media armónica de Precision y Recall:

\begin{equation}
    F1 = 2 \cdot \frac{\text{Precision} \cdot \text{Recall}}{\text{Precision} + \text{Recall}}
\end{equation}

La media armónica penaliza modelos con desbalance extremo entre métricas. Según \textcite{Hafez2025}: F1 $<$70\% indica desempeño insuficiente, F1 70-80\% es aceptable, F1 80-90\% es bueno, y F1 $\geq$90\% es excelente.

\subsubsection{AUC-ROC}

La curva ROC grafica la Tasa de Verdaderos Positivos (Recall) versus Tasa de Falsos Positivos para diferentes umbrales de clasificación. El área bajo la curva (AUC) proporciona una medida agregada independiente del umbral \parencite{Hastie2009}.

Interpretación: AUC = 1,0 indica clasificador perfecto, AUC 0,9-1,0 excelente, AUC 0,8-0,9 bueno, AUC 0,7-0,8 aceptable, AUC = 0,5 equivale a clasificador aleatorio.

\textcite{Murphy2022} recomiendan AUC-ROC $\geq$0,92 para aplicaciones de detección de fraude en producción.

\subsection{Feature Engineering en Detección de Fraude}

Feature engineering es el proceso de transformar datos brutos en representaciones que facilitan el aprendizaje de patrones relevantes \parencite{Geron2022}. En detección de fraude, las features originales (monto, timestamp, usuario) capturan información limitada sobre comportamientos anómalos.

\textcite{Baesens2015} categorizan las features en tres familias:

\begin{enumerate}
    \item \textbf{Features estáticas:} Atributos de baja frecuencia de cambio (país de tarjeta, tipo de cuenta, canal habitual).

    \item \textbf{Features transaccionales:} Características de la transacción actual (monto, hora, canal, comercio).

    \item \textbf{Features comportamentales:} Derivadas del historial del usuario (frecuencia transaccional, desviación del monto respecto al promedio histórico, tiempo desde última transacción, patrones geográficos).
\end{enumerate}

\subsubsection{Agregaciones Temporales}

Las agregaciones temporales capturan patrones de comportamiento en ventanas de tiempo. \textcite{Lucas2019} documenta que estas features son altamente predictivas:

\begin{itemize}
    \item Número de transacciones del usuario en las últimas 24 horas, 7 días, 30 días
    \item Monto total gastado en ventanas temporales
    \item Desviación estándar del monto transaccional del usuario
    \item Tiempo transcurrido desde la última transacción
    \item Número de comercios distintos visitados
\end{itemize}

\subsubsection{Features de Velocidad}

Las features de velocidad miden la tasa de cambio en el comportamiento, detectando actividad de alta frecuencia característica del fraude \parencite{Carcillo2018}:

\begin{itemize}
    \item Velocidad transaccional: transacciones por unidad de tiempo
    \item Cambio en geolocalización: distancia entre IP actual e IP previas
    \item Ratio monto actual versus promedio histórico
    \item Indicador de comercio nuevo (nunca visitado por el usuario)
\end{itemize}

\subsubsection{Prevención de Data Leakage}

Es crítico que las features agregadas usen exclusivamente información disponible antes de la transacción actual, evitando información futura que no estaría disponible en producción \parencite{Geron2022}. Este principio se implementa mediante joins temporales con cláusulas que filtran por timestamp anterior a la transacción actual.

\subsection{Estrategias de Balanceo de Clases}

El desbalanceo de clases es un desafío fundamental en detección de fraude. \textcite{Hafez2025} reportan ratios de clase minoritaria entre 0,1\% y 5\%, lo que genera modelos sesgados hacia la clase mayoritaria.

\subsubsection{SMOTE (Synthetic Minority Over-sampling Technique)}

SMOTE genera instancias sintéticas de la clase minoritaria mediante interpolación lineal entre instancias cercanas \parencite{Geron2022}:

\begin{equation}
    x_{\text{new}} = x_i + \lambda (x_j - x_i) \quad \text{donde } \lambda \sim U(0,1)
\end{equation}

Ventajas: aumenta representación sin duplicar instancias exactas, introduce variabilidad controlada. Limitaciones: puede generar ruido con outliers, no debe aplicarse al test set.

\subsubsection{Class Weights}

Asignación de pesos diferentes a cada clase en la función de pérdida:

\begin{equation}
    \mathcal{L}_{\text{weighted}} = \sum_{i=1}^{n} w_{y_i} \cdot \mathcal{L}(\hat{y}_i, y_i)
\end{equation}

Para un dataset con 1\% de fraude, $w_1 = 99$ penaliza 99 veces más los errores en la clase minoritaria. Scikit-learn implementa esto mediante \texttt{class\_weight='balanced'} \parencite{Pedregosa2011}.

Ventajas sobre SMOTE: no aumenta el tamaño del dataset, no genera datos sintéticos, integración nativa en Random Forest.

\subsection{Validación Temporal en Series Financieras}

\textcite{Geron2022} advierten que la validación cruzada k-fold tradicional es inadecuada para datos con dependencia temporal:

\begin{enumerate}
    \item \textbf{Viola el orden temporal:} K-fold aleatorio puede usar transacciones futuras para predecir pasadas, generando data leakage temporal que infla artificialmente las métricas.

    \item \textbf{Ignora concept drift:} Los patrones de fraude evolucionan; un modelo entrenado con datos de enero puede degradarse en diciembre.

    \item \textbf{No simula producción:} En operación real, el modelo predice transacciones futuras con conocimiento del pasado.
\end{enumerate}

La validación temporal respeta el orden cronológico \parencite{Hastie2009}:

\begin{itemize}
    \item \textbf{Train set:} Transacciones del periodo T1
    \item \textbf{Validation set:} Transacciones del periodo T2 $>$ T1
    \item \textbf{Test set:} Transacciones del periodo T3 $>$ T2
\end{itemize}

Esta estrategia simula el despliegue real: entrenamiento con datos históricos, ajuste de hiperparámetros con datos de validación futuros, evaluación final con datos aún más recientes.

\subsection{Marco Normativo}

Los sistemas de detección de fraude operan bajo marcos normativos que impactan decisiones técnicas.

\subsubsection{PCI DSS (Payment Card Industry Data Security Standard)}

PCI DSS versión 4.0 establece requisitos para procesamiento seguro de información de tarjetas \parencite{NIST2024}:

\begin{itemize}
    \item \textbf{Requisito 10:} Monitoreo y logging de transacciones
    \item \textbf{Requisito 11:} Implementación de controles anti-fraude y detección de anomalías
    \item \textbf{Requisito 3:} Encriptación de datos sensibles
\end{itemize}

\subsubsection{NIST Cybersecurity Framework 2.0}

\textcite{NIST2024} incorporan la función ``Govern'' que enfatiza la gestión del riesgo cibernético como riesgo empresarial. Para sistemas de pago, recomienda:

\begin{itemize}
    \item \textbf{Detectar:} Eventos de seguridad en tiempo real (latencia de inferencia $<$200ms)
    \item \textbf{Responder:} Protocolos documentados ante incidentes
    \item \textbf{Recuperar:} Planes de continuidad (fallback a reglas si modelo falla)
\end{itemize}

\subsubsection{Implicaciones para el Modelo}

Random Forest facilita el cumplimiento regulatorio mediante su capacidad de calcular feature importance, lo que permite explicar las decisiones del modelo ante auditorías. Esta interpretabilidad es relevante para el derecho a explicación contemplado en regulaciones de protección de datos.

% ==================================================================================
% 1.3. DEFINICIÓN DE TÉRMINOS BÁSICOS
% ==================================================================================

\section{Definición de Términos Básicos}

Según \textcite[p. 77]{Hernandez2018}, la definición de términos básicos permite establecer un lenguaje común y evitar ambigüedades en la interpretación de conceptos clave.

\begin{description}
    \item[Machine Learning:] Rama de la inteligencia artificial que permite a los sistemas aprender patrones a partir de datos sin ser programados explícitamente para cada tarea específica \parencite{Geron2022}.

    \item[Aprendizaje Supervisado:] Paradigma de Machine Learning donde el algoritmo aprende a partir de ejemplos etiquetados, estableciendo una función que mapea entradas a salidas conocidas \parencite{James2021}.

    \item[Random Forest:] Algoritmo de ensemble learning que combina múltiples árboles de decisión entrenados con subconjuntos aleatorios de datos, generando predicciones por votación mayoritaria \parencite{Breiman2001}.

    \item[Ensemble Learning:] Técnica que combina múltiples modelos de Machine Learning para obtener predicciones más robustas que cualquier modelo individual \parencite{Hastie2009}.

    \item[Feature Engineering:] Proceso de transformar datos brutos en representaciones que facilitan el aprendizaje de patrones por algoritmos de Machine Learning \parencite{Geron2022}.

    \item[Fraude Transaccional:] Actividad ilícita donde una transacción de pago digital es realizada sin autorización legítima del titular, con propósito de obtener beneficio económico indebido \parencite{Baesens2015}.

    \item[Chargeback:] Proceso mediante el cual un banco emisor revierte una transacción a solicitud del tarjetahabiente, generalmente por fraude o disputa comercial.

    \item[F1-Score:] Media armónica de Precision y Recall que proporciona una medida balanceada del desempeño de clasificación \parencite{Geron2022}.

    \item[Recall (Sensibilidad):] Proporción de casos positivos reales que fueron correctamente identificados por el modelo \parencite{James2021}.

    \item[Precision:] Proporción de predicciones positivas que fueron correctas \parencite{James2021}.

    \item[AUC-ROC:] Área bajo la curva ROC (Receiver Operating Characteristic), medida de capacidad discriminativa independiente del umbral de clasificación \parencite{Hastie2009}.

    \item[Data Leakage:] Uso inadvertido de información que no estaría disponible en producción durante el entrenamiento del modelo, generando estimaciones optimistas del desempeño \parencite{Geron2022}.

    \item[Concept Drift:] Cambio en la distribución de datos o en la relación entre variables a lo largo del tiempo, que puede degradar el desempeño de modelos entrenados con datos históricos \parencite{Murphy2022}.

    \item[SMOTE:] Synthetic Minority Over-sampling Technique, técnica de balanceo que genera instancias sintéticas de la clase minoritaria mediante interpolación \parencite{Geron2022}.

    \item[Class Weights:] Ponderación diferencial de clases en la función de pérdida para compensar desbalanceo en el dataset de entrenamiento \parencite{Pedregosa2011}.

    \item[Validación Temporal:] Estrategia de evaluación que respeta el orden cronológico de los datos, simulando el despliegue real del modelo \parencite{Hastie2009}.

    \item[PCI DSS:] Payment Card Industry Data Security Standard, conjunto de requisitos de seguridad para organizaciones que procesan información de tarjetas de pago.

    \item[SaaS:] Software as a Service, modelo de distribución de software donde las aplicaciones se alojan en la nube y se acceden vía internet.

    \item[Gateway de Pago:] Servicio tecnológico que procesa transacciones de pago entre comerciantes y redes de tarjetas o bancos.
\end{description}

% ==================================================================================
% SÍNTESIS DEL CAPÍTULO
% ==================================================================================

\section*{Síntesis del Capítulo}
\addcontentsline{toc}{section}{Síntesis del Capítulo}

El presente capítulo ha desarrollado la fundamentación teórica de la investigación, cumpliendo con el Objetivo Específico 1 (OE1) de fundamentar teóricamente los modelos de Machine Learning supervisados aplicados a detección de fraude en pagos digitales.

La revisión de antecedentes del periodo 2020-2025 evidencia que Random Forest alcanza consistentemente F1-Scores entre 85\% y 92\% en detección de fraude financiero, con implementaciones exitosas en contextos latinoamericanos similares a TechSport. Los métodos de ensemble learning superan a técnicas tradicionales basadas en reglas estáticas, y la interpretabilidad de Random Forest facilita el cumplimiento de requisitos regulatorios.

Las bases teóricas establecen que el fraude en pagos digitales presenta tipologías identificables (tarjetas robadas, transacciones duplicadas, comportamientos anómalos, identidad sintética) que generan impacto económico significativo. Los sistemas basados en reglas estáticas presentan limitaciones estructurales (ausencia de aprendizaje, alta tasa de falsos positivos, degradación temporal) que justifican la adopción de Machine Learning supervisado.

Random Forest se posiciona como algoritmo adecuado por su interpretabilidad, robustez ante overfitting, manejo de variables mixtas, escalabilidad y capacidad nativa de manejar desbalanceo de clases. Las métricas de evaluación (Precision, Recall, F1-Score, AUC-ROC) permiten cuantificar el desempeño en contextos desbalanceados, donde Recall es prioritario para minimizar fraudes no detectados.

El feature engineering comportamental, las estrategias de balanceo de clases y la validación temporal constituyen componentes metodológicos esenciales para garantizar la generalización del modelo. El marco normativo (PCI DSS, NIST) contextualiza los requisitos regulatorios que el modelo debe satisfacer.

Esta fundamentación teórica proporciona la base conceptual y técnica para el desarrollo del modelo propuesto, con benchmarks cuantitativos alineados con los objetivos de la investigación: F1-Score $\geq$85\%, Recall $\geq$90\%, Precision $\geq$80\%, AUC-ROC $\geq$0,92.

\cleardoublepage
