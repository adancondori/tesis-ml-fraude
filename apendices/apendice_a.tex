% Apéndice A: Código Fuente Completo
\chapter{Código Fuente Completo}
\label{apendice:codigo}

\section{Script de Preprocesamiento}

\begin{lstlisting}[style=python, caption=Preprocesamiento de datos]
import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler, LabelEncoder

def preprocess_data(df):
    """
    Preprocesa los datos transaccionales
    """
    # Eliminar valores nulos
    df = df.dropna()
    
    # Codificar variables categóricas
    le = LabelEncoder()
    categorical_cols = ['canal', 'gateway', 'pais']
    
    for col in categorical_cols:
        df[col + '_encoded'] = le.fit_transform(df[col])
    
    # Normalizar variables numéricas
    scaler = StandardScaler()
    numeric_cols = ['monto', 'hora_dia', 'dia_semana']
    df[numeric_cols] = scaler.fit_transform(df[numeric_cols])
    
    return df
\end{lstlisting}

\section{Script de Entrenamiento}

\begin{lstlisting}[style=python, caption=Entrenamiento del modelo]
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split, cross_val_score
import joblib

# Cargar datos
df = pd.read_csv('datos_transacciones.csv')
X = df.drop(['fraude'], axis=1)
y = df['fraude']

# Dividir datos
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# Entrenar modelo
model = RandomForestClassifier(
    n_estimators=300,
    max_depth=20,
    min_samples_split=5,
    random_state=42
)

model.fit(X_train, y_train)

# Validación cruzada
cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='f1')
print(f"F1-Score promedio (CV): {cv_scores.mean():.4f}")

# Guardar modelo
joblib.dump(model, 'modelo_fraude.pkl')
\end{lstlisting}

\section{Script de Evaluación}

\begin{lstlisting}[style=python, caption=Evaluación del modelo]
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.metrics import roc_auc_score, roc_curve
import matplotlib.pyplot as plt

# Predecir
y_pred = model.predict(X_test)
y_pred_proba = model.predict_proba(X_test)[:, 1]

# Métricas
print(classification_report(y_test, y_pred))

# Matriz de confusión
cm = confusion_matrix(y_test, y_pred)
print("Matriz de Confusión:")
print(cm)

# AUC-ROC
auc = roc_auc_score(y_test, y_pred_proba)
print(f"AUC-ROC: {auc:.4f}")

# Curva ROC
fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)
plt.plot(fpr, tpr, label=f'AUC = {auc:.4f}')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Curva ROC')
plt.legend()
plt.savefig('curva_roc.png')
\end{lstlisting}
