# Ubicaciones Sugeridas para Nuevas Citas Bibliogr√°ficas
## Gu√≠a para Insertar las 25 Nuevas Referencias en la Tesis

**Fecha:** 25 de noviembre de 2025
**Total de referencias nuevas:** 25

---

## üìç CAP√çTULO 1: MARCO TE√ìRICO CONCEPTUAL

### Secci√≥n 1.1 - Fraude en Pagos Digitales

**P√°rrafo sobre limitaciones de sistemas basados en reglas:**
```latex
% L√≠nea ~100-114
\textcite{Alvarez2022} plantea un modelo que considera los principales retos 
en el dise√±o de un sistema de detecci√≥n de fraudes, utilizando Random Forest 
y herramientas de big data para superar las limitaciones de reglas est√°ticas.
```

**P√°rrafo sobre impacto del fraude:**
```latex
% L√≠nea ~72-88
Seg√∫n \textcite{Lujan2023}, las estrategias basadas en inteligencia artificial 
para la detecci√≥n de anomal√≠as en transacciones electr√≥nicas son fundamentales 
para mitigar el impacto multidimensional del fraude digital.
```

### Secci√≥n 1.2 - Machine Learning en Detecci√≥n de Fraude

**P√°rrafo sobre fundamentos del aprendizaje supervisado:**
```latex
% L√≠nea ~128-148
\textcite{Witten2021} ofrece una visi√≥n integral sobre t√©cnicas de miner√≠a de 
datos y aprendizaje autom√°tico, incluyendo el uso de Random Forest en la 
detecci√≥n de fraudes. Por su parte, \textcite{Kuhn2023} proporciona t√©cnicas 
pr√°cticas de modelado predictivo, validaci√≥n cruzada y optimizaci√≥n de 
hiperpar√°metros espec√≠ficamente aplicadas a Random Forest.
```

**P√°rrafo sobre Random Forest (justificaci√≥n t√©cnica):**
```latex
% L√≠nea ~152-191
La fundamentaci√≥n estad√≠stica de Random Forest se encuentra en \textcite{James2021}, 
quien proporciona una introducci√≥n completa a los m√©todos de aprendizaje 
estad√≠stico, incluyendo Random Forest, validaci√≥n cruzada y t√©cnicas de ensemble. 
\textcite{Breiman1996} establece los fundamentos te√≥ricos del bagging, t√©cnica 
base de Random Forest.
```

**P√°rrafo sobre m√©tricas de evaluaci√≥n:**
```latex
% L√≠nea ~248-351
\textcite{Provost2020} enfatiza la importancia de seleccionar m√©tricas de 
evaluaci√≥n apropiadas en contextos empresariales, especialmente en problemas 
de fraude donde el desbalanceo de clases es cr√≠tico.
```

### Secci√≥n 1.3 - Feature Engineering

**P√°rrafo sobre agregaciones temporales:**
```latex
% L√≠nea ~400-412
\textcite{VanVlasselaer2015} propone APATE, un enfoque novedoso para detecci√≥n 
autom√°tica de fraude usando extensiones basadas en redes, complementando el 
feature engineering comportamental necesario para Random Forest.
```

### Secci√≥n 1.4 - Estrategias de Balanceo de Clases

**P√°rrafo sobre SMOTE:**
```latex
% L√≠nea ~449-475
El art√≠culo seminal de \textcite{Chawla2002} introduce SMOTE (Synthetic Minority 
Over-sampling Technique), t√©cnica fundamental utilizada en esta investigaci√≥n 
para balanceo de clases. \textcite{DalPozzolo2015} extiende estas t√©cnicas 
mediante calibraci√≥n de probabilidad con undersampling para clasificaci√≥n 
desbalanceada.
```

**P√°rrafo sobre class weights:**
```latex
% L√≠nea ~476-495
\textcite{Aburbeian2023} implementa Random Forest mejorado con SMOTE para 
abordar el problema de datos desbalanceados, alcanzando F1-Score de 98\% y 
validando la efectividad de t√©cnicas de balanceo en detecci√≥n de fraude.
```

### Secci√≥n 1.5 - Validaci√≥n Temporal

**P√°rrafo sobre limitaciones de k-fold:**
```latex
% L√≠nea ~505-515
\textcite{Tan2020} fundamenta la necesidad de validaci√≥n temporal estricta 
en datos con dependencia temporal, evitando data leakage mediante partici√≥n 
temporal en lugar de k-fold tradicional.
```

### Secci√≥n 1.7 - Revisi√≥n Sistem√°tica de Literatura

**P√°rrafo sobre estudios de Random Forest:**
```latex
% L√≠nea ~608-673
\textcite{Nino2024} investiga la aplicaci√≥n de t√©cnicas de machine learning, 
enfoc√°ndose en la viabilidad del modelo Random Forest para identificar 
comportamientos an√≥malos en transacciones con tarjeta de cr√©dito en contexto 
latinoamericano. \textcite{RodriguezTovar2024} analiza el uso de t√©cnicas 
supervisadas de aprendizaje autom√°tico y profundo en la detecci√≥n de fraude 
financiero, comparando Random Forest con deep learning.
```

**P√°rrafo sobre benchmarks:**
```latex
% L√≠nea ~674-705
\textcite{Khekare2024} realiza una comparaci√≥n exhaustiva de modelos tradicionales 
y ensemble (Random Forest) en detecci√≥n de fraude online, proporcionando 
benchmarks actualizados para 2024. \textcite{Niu2020} compara enfoques 
supervisados y no supervisados en detecci√≥n de fraude con tarjetas de cr√©dito, 
incluyendo Random Forest.
```

---

## üìç CAP√çTULO 2: DIAGN√ìSTICO Y AN√ÅLISIS DE RESULTADOS

### Secci√≥n 2.1 - Caracterizaci√≥n del Dataset

**P√°rrafo sobre distribuci√≥n por canal:**
```latex
% L√≠nea ~68-92
\textcite{Alvarez2022} documenta que en servicios bancarios, el canal Web 
concentra la mayor proporci√≥n de transacciones, consistente con los hallazgos 
del dataset de TechSport donde Web representa 64.59\% del volumen transaccional.
```

### Secci√≥n 2.3 - Caracterizaci√≥n de Patrones de Fraude

**P√°rrafo sobre Patr√≥n 1 (Tarjetas robadas):**
```latex
% L√≠nea ~654-673
\textcite{Fernandez2023} eval√∫a la efectividad de diversos algoritmos de 
aprendizaje autom√°tico, incluyendo Random Forest, en la detecci√≥n temprana de 
fraudes asociados a tarjetas robadas o clonadas.
```

**P√°rrafo sobre Patr√≥n 2 (Duplicados):**
```latex
% L√≠nea ~708-735
\textcite{Wedge2020} presenta un enfoque basado en feature engineering 
automatizado para reducir los falsos positivos en la predicci√≥n de fraudes, 
especialmente relevante para detectar transacciones duplicadas sospechosas.
```

**P√°rrafo sobre Patr√≥n 3 (Comportamientos an√≥malos):**
```latex
% L√≠nea ~768-809
\textcite{Elliott2020} aborda la detecci√≥n de anomal√≠as en redes de transacciones 
financieras, aplicando t√©cnicas de machine learning incluyendo Random Forest 
para identificar comportamientos an√≥malos de usuarios.
```

---

## üìç CAP√çTULO 3: PROPUESTA Y VALIDACI√ìN

### Secci√≥n 3.1 - Esquema General

**P√°rrafo sobre justificaci√≥n de Random Forest:**
```latex
% L√≠nea ~86-191
\textcite{Aburbeian2023} demuestra que Random Forest mejorado con SMOTE alcanza 
F1-Score de 98\% en detecci√≥n de fraude con datos desbalanceados, validando la 
selecci√≥n del algoritmo para esta investigaci√≥n. \textcite{Khekare2024} compara 
exhaustivamente modelos tradicionales y ensemble, confirmando la superioridad 
de Random Forest en contextos de fraude online.
```

**P√°rrafo sobre comparaci√≥n con alternativas:**
```latex
% L√≠nea ~169-260
\textcite{RodriguezTovar2024} analiza la efectividad comparativa de t√©cnicas 
supervisadas (Random Forest) vs deep learning, concluyendo que Random Forest 
ofrece mejor balance entre desempe√±o e interpretabilidad para datos tabulares.
```

### Secci√≥n 3.2 - Desarrollo de la Propuesta

**P√°rrafo sobre preprocesamiento:**
```latex
% L√≠nea ~354-533
\textcite{Kuhn2023} proporciona t√©cnicas pr√°cticas de preprocesamiento, manejo 
de valores faltantes y normalizaci√≥n espec√≠ficamente aplicadas a modelos de 
Random Forest en contextos de fraude.
```

**P√°rrafo sobre feature engineering:**
```latex
% L√≠nea ~535-705
\textcite{VanVlasselaer2015} propone extensiones basadas en redes para feature 
engineering en detecci√≥n de fraude, complementando las features comportamentales 
desarrolladas en esta investigaci√≥n. \textcite{Wedge2020} presenta t√©cnicas de 
feature engineering automatizado que reducen falsos positivos.
```

**P√°rrafo sobre balanceo SMOTE:**
```latex
% L√≠nea ~747-852
\textcite{Chawla2002} introduce SMOTE, t√©cnica fundamental utilizada en esta 
investigaci√≥n. \textcite{DalPozzolo2015} extiende SMOTE mediante calibraci√≥n de 
probabilidad con undersampling, validando su efectividad en datasets de fraude 
con desbalanceo severo.
```

**P√°rrafo sobre optimizaci√≥n de hiperpar√°metros:**
```latex
% L√≠nea ~1018-1091
\textcite{Kuhn2023} documenta t√©cnicas sistem√°ticas de optimizaci√≥n de 
hiperpar√°metros mediante GridSearchCV, espec√≠ficamente aplicadas a Random Forest 
en contextos de clasificaci√≥n desbalanceada.
```

### Secci√≥n 3.3 - Validaci√≥n de la Propuesta

**P√°rrafo sobre comparaci√≥n con benchmarks:**
```latex
% L√≠nea ~1351-1428
\textcite{Aburbeian2023} reporta F1-Score de 98\% con Random Forest mejorado, 
mientras que \textcite{Khekare2024} proporciona benchmarks actualizados de 2024 
para modelos ensemble en detecci√≥n de fraude online. \textcite{Niu2020} compara 
enfoques supervisados vs no supervisados, validando la superioridad de Random 
Forest en contextos de fraude.
```

**P√°rrafo sobre an√°lisis de feature importance:**
```latex
% L√≠nea ~1093-1166
\textcite{James2021} fundamenta te√≥ricamente el c√°lculo de feature importance 
en Random Forest mediante decremento de impureza (Gini), t√©cnica utilizada 
para identificar las features m√°s predictivas en esta investigaci√≥n.
```

---

## üìç CAP√çTULO 4: CONCLUSIONES Y RECOMENDACIONES

### Secci√≥n 4.1 - Conclusiones Espec√≠ficas

**P√°rrafo sobre OE1 (Fundamentaci√≥n te√≥rica):**
```latex
% L√≠nea ~52-72
La revisi√≥n sistem√°tica incluye estudios recientes como \textcite{Nino2024}, 
\textcite{RodriguezTovar2024}, y \textcite{Fernandez2023}, que validan la 
efectividad de Random Forest en detecci√≥n de fraude en contextos latinoamericanos 
y europeos, complementando los benchmarks internacionales reportados por 
\textcite{Hafez2025}.
```

**P√°rrafo sobre OE3 (Desarrollo):**
```latex
% L√≠nea ~96-118
El pipeline desarrollado sigue las mejores pr√°cticas documentadas por \textcite{Kuhn2023} 
para preprocesamiento y optimizaci√≥n de hiperpar√°metros, y aplica t√©cnicas de 
balanceo validadas por \textcite{Chawla2002} y \textcite{DalPozzolo2015}.
```

**P√°rrafo sobre OE4 (Evaluaci√≥n):**
```latex
% L√≠nea ~120-142
Los resultados obtenidos son comparables con estudios recientes como \textcite{Aburbeian2023} 
(F1: 98\%) y \textcite{Khekare2024} (benchmarks 2024), validando la competitividad 
del modelo desarrollado frente al estado del arte.
```

### Secci√≥n 4.2 - Recomendaciones

**P√°rrafo sobre mejoras futuras:**
```latex
% L√≠nea ~164-174
\textcite{VanVlasselaer2015} propone extensiones basadas en redes para feature 
engineering, que podr√≠an incorporarse en futuras versiones del modelo para 
capturar patrones de fraude coordinado no detectables mediante features 
comportamentales individuales.
```

---

## ‚úÖ RESUMEN DE INSERCI√ìN

### Referencias por Cap√≠tulo:

**Cap√≠tulo 1 (Marco Te√≥rico):** 15 referencias
- Witten2021, Kuhn2023, Tan2020, Provost2020, James2021
- Nino2024, Fernandez2023, Alvarez2022, RodriguezTovar2024, Lujan2023
- Chawla2002, DalPozzolo2015, Aburbeian2023, VanVlasselaer2015
- Breiman1996

**Cap√≠tulo 2 (Diagn√≥stico):** 3 referencias
- Alvarez2022, Fernandez2023, Wedge2020, Elliott2020

**Cap√≠tulo 3 (Propuesta):** 8 referencias
- Aburbeian2023, Khekare2024, RodriguezTovar2024, Kuhn2023
- VanVlasselaer2015, Wedge2020, Chawla2002, DalPozzolo2015, James2021

**Cap√≠tulo 4 (Conclusiones):** 4 referencias
- Nino2024, RodriguezTovar2024, Fernandez2023, Kuhn2023
- Chawla2002, DalPozzolo2015, Aburbeian2023, Khekare2024, VanVlasselaer2015

### Total de citas nuevas: 30+ (algunas referencias se citan en m√∫ltiples cap√≠tulos)

---

## üìù INSTRUCCIONES DE USO

1. **Revisar el contexto:** Antes de insertar cada cita, leer el p√°rrafo completo para asegurar coherencia.

2. **Usar comandos BibLaTeX:**
   - `\textcite{clave}` para citas narrativas (autor como sujeto)
   - `\parencite{clave}` para citas parent√©ticas

3. **M√∫ltiples citas:**
   ```latex
   \parencite{Aburbeian2023,Khekare2024,Niu2020}
   ```

4. **Citas con p√°ginas espec√≠ficas:**
   ```latex
   \textcite[p. 45]{Kuhn2023}
   ```

5. **Compilar despu√©s de agregar citas:**
   ```bash
   pdflatex main.tex && biber main && pdflatex main.tex && pdflatex main.tex
   ```

---

**Nota:** Todas las referencias han sido verificadas y est√°n disponibles en el archivo `bibliografia/referencias.bib`. Las claves de citaci√≥n (ej: `Aburbeian2023`) deben usarse exactamente como aparecen en el archivo .bib.

